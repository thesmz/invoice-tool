import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from google.cloud import documentai_v1 as documentai
from google.api_core.client_options import ClientOptions
import re
import time

st.set_page_config(page_title="Reconciliation", layout="wide", page_icon="‚öñÔ∏è")

# --- AUTHENTICATION ---
if "gcp_service_account" not in st.secrets:
    st.error("Secrets not found. Please setup secrets in app.py first.")
    st.stop()

creds_dict = dict(st.secrets["gcp_service_account"])

# --- HELPER: CALL GOOGLE DOC AI (THE "EYES") ---
def get_text_from_docai(file_content, project_id, loc, proc_id):
    """Google OCR„Çí‰Ωø„Å£„Å¶ÂÖ®„ÉÜ„Ç≠„Çπ„Éà„ÇíÂèñÂæó"""
    opts = ClientOptions(api_endpoint=f"{loc}-documentai.googleapis.com")
    creds = Credentials.from_service_account_info(creds_dict)
    client = documentai.DocumentProcessorServiceClient(client_options=opts, credentials=creds)
    
    name = client.processor_path(project_id, loc, proc_id)
    raw_document = documentai.RawDocument(content=file_content, mime_type="application/pdf")
    request = documentai.ProcessRequest(name=name, raw_document=raw_document)
    
    result = client.process_document(request=request)
    return result.document.text

# --- PARSER: NOISE FILTER LOGIC ---
def parse_docai_text(full_text):
    """
    ÈÄè„Åã„ÅóÊñáÂ≠ó(Rakuten Bank)„Å†„Çâ„Åë„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„Åã„Çâ„ÄÅ
    Ê≠£Ë¶èË°®Áèæ„Çí‰Ωø„Å£„Å¶ÊúâÂäπ„Å™ÂèñÂºïË°å„Å†„Åë„ÇíÊïëÂá∫„Åô„Çã„ÄÇ
    """
    transactions = []
    
    # 1. ÊîπË°å„ÅßÂàÜÂâ≤
    lines = full_text.split('\n')
    
    # Êó•‰ªò„Éë„Çø„Éº„É≥ (2025/11/01 „Å™„Å©)
    # Ë°å„ÅÆ„Å©„Åì„Åã„Å´„Åì„ÅÆÊó•‰ªò„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„Çå„Å∞„ÄÅ„Åù„Çå„ÅØÂèñÂºïË°å„ÅÆÂèØËÉΩÊÄß„ÅåÈ´ò„ÅÑ
    date_pattern = re.compile(r'(\d{4}/\d{1,2}/\d{1,2})')
    
    for line in lines:
        line = line.strip()
        if not line: continue
        
        # 2. Âº∑Âäõ„Å™„Éï„Ç£„É´„Çø„É™„É≥„Ç∞ÔºöÊó•‰ªò„ÅåÂê´„Åæ„Çå„Å™„ÅÑË°å„ÅØÂç≥Â∫ß„Å´Êç®„Å¶„Çã
        # „Åì„Çå„Å´„Çà„Çä "Rakuten Bank Ê•ΩÂ§©ÈäÄË°å..." „Å†„Åë„ÅÆË°å„ÇíÁÑ°Ë¶ñ„Åß„Åç„Åæ„Åô
        date_match = date_pattern.search(line)
        if not date_match:
            continue
            
        # Êó•‰ªò„ÇíÂèñÂæó
        date_str = date_match.group(1)
        
        # 3. „Éé„Ç§„Ç∫Èô§ÂéªÔºàÈÄè„Åã„ÅóÊñáÂ≠ó„ÇíÊ∂à„ÅôÔºâ
        # Ë°å„ÅÆ‰∏≠„Åã„Çâ "Rakuten", "Bank", "Ê•ΩÂ§©", "ÈäÄË°å" „Å™„Å©„ÅÆ„Éé„Ç§„Ç∫„ÇíÈô§Âéª
        # „Åü„Å†„Åó„ÄÅ„Éô„É≥„ÉÄ„ÉºÂêç„Å´„Åì„Çå„Çâ„ÅåÂê´„Åæ„Çå„ÇãÂèØËÉΩÊÄß„ÇÇ„Çº„É≠„Åß„ÅØ„Å™„ÅÑ„ÅÆ„ÅßÊÖéÈáç„Å´„ÄÅ
        # „Åæ„Åö„ÅØÂçòÁ¥î„Å´„Çπ„Éö„Éº„Çπ„ÅßÂàÜËß£„Åó„Å¶Ëß£Êûê„Åô„Çã
        
        # Ë°åÂÜÖ„ÅÆÊó•‰ªò„Çà„Çä„ÄåÂæå„Çç„Äç„Å´„ÅÇ„Çã„ÉÜ„Ç≠„Çπ„Éà„ÇíÂèñÂæó
        # ‰æã: "Rakuten 2025/11/04 „Ç´Ôºâ„Ç´„Ç¨„É§ 150,000 Bank" -> "„Ç´Ôºâ„Ç´„Ç¨„É§ 150,000 Bank"
        start_idx = line.find(date_str) + len(date_str)
        content_after_date = line[start_idx:].strip()
        
        # „Éà„Éº„ÇØ„É≥ÂåñÔºàÁ©∫ÁôΩ„ÅßÂàÜÂâ≤Ôºâ
        parts = content_after_date.split()
        
        # 4. Êï∞Â≠óÔºàÈáëÈ°çÔºâ„ÇíÊé¢„ÅôÔºàÂæå„Çç„Åã„ÇâÔºâ
        numeric_values = []
        valid_indices = []
        
        for i in range(len(parts) - 1, -1, -1):
            token = parts[i]
            # „Ç´„É≥„Éû„Å®ÂÜÜË®òÂè∑„ÇíÈô§Âéª
            clean = token.replace(',', '').replace('¬•', '').replace('\\', '')
            
            # Êï∞Â≠ó„Åã„Å©„ÅÜ„Åã„ÉÅ„Çß„ÉÉ„ÇØÔºà„Éû„Ç§„Éä„Çπ„ÇÇËÄÉÊÖÆÔºâ
            if clean.replace('-', '').isdigit():
                numeric_values.append(int(clean))
                valid_indices.append(i)
            else:
                # Êï∞Â≠ó‰ª•Â§ñ„ÅÆÊñáÂ≠ó„ÅåÂá∫„Åü„Çâ„ÄÅ„Åù„Åì„ÅåÈáëÈ°ç„Ç®„É™„Ç¢„ÅÆÂ¢ÉÁïåÁ∑ö„Å®„Åø„Å™„Åô
                # „Åü„Å†„Åó„ÄÅ"Bank" „Å®„Åã "Rakuten" „Åø„Åü„ÅÑ„Å™ÂçòË™û„ÅåÊú´Â∞æ„Å´„Å§„ÅÑ„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çã„ÅÆ„Åß
                # „ÇÇ„ÅÜÂ∞ë„ÅóË≥¢„ÅèÂà§ÂÆö„Åô„Çã
                
                # „ÇÇ„ÅóÊó¢„Å´2„Å§‰ª•‰∏ä„ÅÆÊï∞Â≠óÔºàÊÆãÈ´ò„Å®Âá∫ÈáëÈ°çÔºâ„ÅåË¶ã„Å§„Åã„Å£„Å¶„ÅÑ„Çå„Å∞ÁµÇ‰∫Ü
                if len(numeric_values) >= 2:
                    break
        
        # numeric_values „ÅØÂæå„Çç„Åã„ÇâÈ†Ü„Å´ÂÖ•„Å£„Å¶„ÅÑ„Çã [ÊÆãÈ´ò, ÂÖ•ÈáëÈ°ç?, Âá∫ÈáëÈ°ç?]
        
        if len(numeric_values) >= 1:
            # ÈáëÈ°çÂÄôË£ú„ÅåË¶ã„Å§„Åã„Å£„Åü
            
            # 5. Âá∫ÈáëÈ°çÔºàWithdrawalÔºâ„ÇíÁâπÂÆö„Åô„Çã
            # ÈÄöÂ∏∏„ÄÅ‰∏ÄÁï™Âè≥„Åå„ÄåÊÆãÈ´ò„Äç„ÄÅ„Åù„ÅÆÂ∑¶„Åå„ÄåÂÖ•Èáë„Äç„ÄÅ„Åù„ÅÆÂ∑¶„Åå„ÄåÂá∫Èáë„Äç
            # Âá∫Èáë„Åå„ÅÇ„ÇãË°å„ÅØ„ÄÅÊï∞Â≠ó„Åå2„Å§ÔºàÂá∫Èáë„ÄÅÊÆãÈ´òÔºâ„Åæ„Åü„ÅØ3„Å§ÔºàÂá∫Èáë„ÄÅ0„ÄÅÊÆãÈ´òÔºâ‰∏¶„Å∂„Åì„Å®„ÅåÂ§ö„ÅÑ
            
            target_amount = 0
            is_withdrawal = False
            
            # Êï∞Â≠ó„Åå2„Å§‰ª•‰∏ä„ÅÇ„ÇãÂ†¥Âêà„ÄÅ2Áï™ÁõÆÔºàÂæå„Çç„Åã„Çâ2Áï™ÁõÆÔºâ„ÇíÂá∫Èáë„Å®„Åø„Å™„Åô
            if len(numeric_values) >= 2:
                target_amount = numeric_values[1] # 0„ÅåÊÆãÈ´ò„ÄÅ1„ÅåÂá∫ÈáëorÂÖ•Èáë
                
                # „Åì„Åì„ÅßÂà§ÂÆöÔºö„ÇÇ„Åó„Åì„ÅÆË°å„Åå„ÄåÂÖ•Èáë„ÄçË°å„Å™„Çâ„ÄÅ„Åì„ÅÆ„É≠„Ç∏„ÉÉ„ÇØ„Å†„Å®ÂÖ•ÈáëÈ°ç„ÇíÊãæ„Å£„Å¶„Åó„Åæ„ÅÜ„ÄÇ
                # „Åó„Åã„Åó‰ªä„ÅØ„ÄåÊîØÊâï„ÅÑÊ∂àËæº„Äç„ÉÑ„Éº„É´„Å™„ÅÆ„Åß„ÄÅ„ÅÇ„Åà„Å¶„Åù„ÅÆ„Åæ„ÅæÊãæ„ÅÑ„ÄÅ
                # DB„Å®„ÅÆÁÖßÂêàÊôÇ„Å´„Éû„ÉÉ„ÉÅ„Åó„Å™„Åë„Çå„Å∞ÁÑ°Ë¶ñ„Åï„Çå„Çã„ÄÅ„Å®„ÅÑ„ÅÜÊâã„ÇÇ„ÅÇ„Çã„ÄÇ
                # Á∞°ÊòìÁöÑ„Å´„ÄÅ„Åì„ÅÆÊï∞ÂÄ§„Åå0„Çà„ÇäÂ§ß„Åç„Åë„Çå„Å∞Êé°Áî®
                if target_amount > 0:
                    is_withdrawal = True
            
            elif len(numeric_values) == 1:
                # Êï∞Â≠ó„Åå1„Å§„Åó„Åã„Å™„ÅÑÔºàÊÆãÈ´ò„Åó„Åã„Å™„ÅÑÔºüÔºâÂ†¥Âêà„ÅØÁÑ°Ë¶ñ„ÄÅ„Åæ„Åü„ÅØ„Åù„Çå„ÅåÈáëÈ°ç„Åã„ÇÇÔºü
                # ÈÄöÂ∏∏„ÅØÊÆãÈ´ò„Å†„ÅëË°å„Å´„ÅØ„Å™„Çâ„Å™„ÅÑ„ÅÆ„Åß„ÄÅËß£Êûê„Éü„Çπ„ÅÆÂèØËÉΩÊÄß„ÅÇ„Çä
                continue

            if is_withdrawal:
                # 6. „Éô„É≥„ÉÄ„ÉºÂêçÔºàDescriptionÔºâ„ÅÆÊäΩÂá∫
                # Êó•‰ªò„ÅÆÂæå„Çç„Åã„Çâ„ÄÅÊúÄÂàù„Å´Ë¶ã„Å§„Åë„ÅüÊï∞Â≠ó„ÅÆÂâç„Åæ„Åß
                
                # Êï∞Â≠ó„ÅåÂßã„Åæ„Å£„Åü‰ΩçÁΩÆÔºàparts„ÅÆ„Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÔºâ
                first_number_index = valid_indices[-1] # valid_indices„ÅØÂæå„Çç„Åã„ÇâÈ†Ü„Å´ÂÖ•„Å£„Å¶„Çã„ÅÆ„ÅßÊúÄÂæå„Åå‰∏ÄÁï™Â∑¶„ÅÆÊï∞Â≠ó
                
                # „Éô„É≥„ÉÄ„ÉºÂêçÈÉ®ÂàÜ„ÅÆ„Éà„Éº„ÇØ„É≥„ÇíÂèñÂæó
                desc_tokens = parts[:first_number_index]
                
                # „Éé„Ç§„Ç∫Èô§Âéª: "Rakuten", "Bank", "Ê•ΩÂ§©", "ÈäÄË°å" „ÅåÂçòÁã¨„ÅßÊ∑∑„Åñ„Å£„Å¶„ÅÑ„Åü„ÇâÊ∂à„Åô
                clean_desc_tokens = []
                for t in desc_tokens:
                    # ÂÆåÂÖ®„Å´‰∏ÄËá¥„Åô„Çã„Éé„Ç§„Ç∫ÂçòË™û„ÇíÈô§Â§ñÔºàÈÉ®ÂàÜ‰∏ÄËá¥„Å†„Å®Á§æÂêç„ÅåÊ∂à„Åà„ÇãÊÅê„Çå„ÅÇ„ÇäÔºâ
                    if t.lower() not in ['rakuten', 'bank', 'Ê•ΩÂ§©', 'ÈäÄË°å', 'Â§©ÈäÄË°å', 'Ë°å']:
                        clean_desc_tokens.append(t)
                
                vendor_name = " ".join(clean_desc_tokens)
                
                # Á©∫„Åß„Å™„Åë„Çå„Å∞ËøΩÂä†
                if vendor_name:
                    transactions.append({
                        "Date": date_str,
                        "Bank Description": vendor_name,
                        "Amount": target_amount
                    })
                
    return pd.DataFrame(transactions)

# --- HELPER: GOOGLE SHEETS ---
def load_bank_mapping(sheet_url):
    try:
        scopes = ['https://www.googleapis.com/auth/spreadsheets']
        creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
        client = gspread.authorize(creds)
        sheet = client.open_by_url(sheet_url).worksheet("Bank Mapping")
        records = sheet.get_all_values()
        mapping = {}
        for row in records[1:]:
            if len(row) >= 2 and row[0]:
                mapping[row[0].strip()] = row[1].strip()
        return mapping
    except:
        return {}

def add_unknowns_to_sheet(sheet_url, new_names):
    try:
        scopes = ['https://www.googleapis.com/auth/spreadsheets']
        creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
        client = gspread.authorize(creds)
        sheet = client.open_by_url(sheet_url).worksheet("Bank Mapping")
        rows = [[name, ""] for name in new_names]
        sheet.append_rows(rows)
        return True
    except:
        return False

# --- MAIN APP ---
st.title("‚öñÔ∏è Monthly Reconciliation (Powered by Google AI)")

with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    sheet_url = st.text_input("Google Sheet URL", placeholder="https://docs.google.com/spreadsheets/d/...")
    
    with st.expander("Doc AI Settings"):
        project_id = st.text_input("Project ID", value="receipt-processor-479605")
        location = st.selectbox("Location", ["us", "eu"], index=0)
        processor_id = st.text_input("Processor ID", value="88cff36a297265dc")

if not sheet_url:
    st.info("Please enter your Google Sheet URL.")
    st.stop()

# 1. UPLOAD
uploaded_file = st.file_uploader("1. Upload Rakuten PDF", type="pdf")

if uploaded_file:
    # A. Use Google AI to Read Text (The "Eyes")
    with st.spinner("ü§ñ Google AI is reading the Japanese text..."):
        file_content = uploaded_file.read()
        try:
            full_text = get_text_from_docai(file_content, project_id, location, processor_id)
            bank_df = parse_docai_text(full_text)
        except Exception as e:
            st.error(f"Google AI Failed: {e}")
            st.stop()
    
    if bank_df.empty:
        st.error("AI read the file but could not extract valid transactions.")
        with st.expander("See Raw AI Text (Debug)"):
            st.text(full_text)
        st.stop()
        
    st.success(f"‚úÖ AI successfully extracted {len(bank_df)} transactions!")

    # B. Load System Data
    try:
        scopes = ['https://www.googleapis.com/auth/spreadsheets']
        creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
        client = gspread.authorize(creds)
        
        sheet = client.open_by_url(sheet_url).sheet1
        sys_df = pd.DataFrame(sheet.get_all_records())
        
        # Smart Column Finder
        status_col = next((c for c in sys_df.columns if "Status" in c), None)
        fb_col = next((c for c in sys_df.columns if "FB" in c and "Amount" in c), None)
        vendor_col = next((c for c in sys_df.columns if "Vendor" in c), None)
        
        if not all([status_col, fb_col, vendor_col]):
            st.error("Missing columns in Google Sheet. Check 'Status', 'Vendor Name', 'FB Amount'.")
            st.stop()
            
        paid_invoices = sys_df[sys_df[status_col] == "Paid"].copy()
    except Exception as e:
        st.error(f"Error loading sheet: {e}")
        st.stop()

    # C. Load Map
    mapping_dict = load_bank_mapping(sheet_url)
    
    # D. Match Logic
    matches = []
    unmatched_bank = []
    unknown_names = set()
    
    for idx, row in bank_df.iterrows():
        bank_desc = row['Bank Description']
        bank_amt = row['Amount']
        
        # Translate
        trans_name = "Unknown"
        if bank_desc in mapping_dict:
            trans_name = mapping_dict[bank_desc]
        else:
            for k, v in mapping_dict.items():
                if k in bank_desc:
                    trans_name = v
                    break
        
        if trans_name == "Unknown":
            unknown_names.add(bank_desc)
            
        # Match
        match = paid_invoices[
            (paid_invoices[vendor_col] == trans_name) & 
            (paid_invoices[fb_col] == bank_amt)
        ]
        
        if not match.empty:
            matches.append({
                "Date": row['Date'],
                "Bank Name": bank_desc,
                "System Name": trans_name,
                "Amount": f"¬•{bank_amt:,.0f}",
                "Status": "‚úÖ Match"
            })
        else:
            unmatched_bank.append({
                "Date": row['Date'],
                "Bank Name": bank_desc,
                "Translated": trans_name,
                "Amount": f"¬•{bank_amt:,.0f}",
                "Status": "‚ùå Missing"
            })

    # E. Display
    st.divider()
    if unknown_names:
        st.warning(f"Found {len(unknown_names)} unknown names.")
        if st.button("‚òÅÔ∏è Auto-Add Unknowns"):
            add_unknowns_to_sheet(sheet_url, list(unknown_names))
            st.success("Added! Please refresh.")
    
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("‚úÖ Matched")
        st.dataframe(matches)
    with c2:
        st.subheader("‚ùå Unmatched")
        st.dataframe(unmatched_bank)
